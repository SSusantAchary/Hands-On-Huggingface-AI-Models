# ğŸ—£ï¸ Small Language Model Repository

Welcome to the **Small Language Model Repository**! This project focuses on building lightweight, domain-specific language models for diverse applications, including multilingual text and audio-based processing.

---

## ğŸ§ List of Audio Language Models

Below are 10 popular audio language models with their licensing details:

| ğŸ™ï¸ **Model**            | ğŸŒ **Description**                                                                                      | ğŸ“œ **License**      | ğŸ”— **More Info**                             |
|--------------------------|------------------------------------------------------------------------------------------------------|---------------------|---------------------------------------------|
| **1. Whisper by OpenAI** ğŸ§  | Robust speech recognition model supporting multilingual transcription and translation.                  | MIT License         | [GitHub](https://github.com/openai/whisper) |
| **2. Wav2Vec 2.0 by Facebook AI** ğŸŒŠ | Self-supervised learning for speech recognition with outstanding performance on ASR tasks.          | Apache 2.0          | [GitHub](https://github.com/facebookresearch/fairseq/tree/main/examples/wav2vec) |
| **3. DeepSpeech by Mozilla** ğŸ”Š | Open-source speech-to-text model inspired by Baidu's DeepSpeech research.                          | MPL 2.0             | [GitHub](https://github.com/mozilla/DeepSpeech) |
| **4. Kaldi** ğŸ¤            | Toolkit for speech recognition with support for advanced algorithms and flexible architectures.      | Apache 2.0          | [Website](https://kaldi-asr.org/)           |
| **5. SpeechBrain** ğŸ§      | All-in-one toolkit for speech technologies, including ASR, speaker recognition, and enhancement.     | Apache 2.0          | [GitHub](https://github.com/speechbrain/speechbrain) |
| **6. Coqui STT** ğŸ¸        | TTS and ASR model forked from Mozilla DeepSpeech, focusing on speed and ease of use.                 | MPL 2.0             | [GitHub](https://github.com/coqui-ai/STT)   |
| **7. OpenSLR** ğŸ—ƒï¸         | Repository of open speech and language resources for building speech models.                        | Various (depends on resource) | [Website](http://www.openslr.org/)          |
| **8. PaddleSpeech** ğŸ¼     | End-to-end speech toolkit by Baidu focusing on ASR, TTS, and other speech-related tasks.            | Apache 2.0          | [GitHub](https://github.com/PaddlePaddle/PaddleSpeech) |
| **9. ESPnet** ğŸš€          | End-to-end speech processing toolkit for ASR, TTS, and STT with modern neural architectures.         | Apache 2.0          | [GitHub](https://github.com/espnet/espnet)  |
| **10. Jasper by NVIDIA** âš¡ | End-to-end ASR model optimized for GPUs, focusing on accuracy and training speed.                   | Apache 2.0          | [GitHub](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/SpeechRecognition/Jasper) |

---
## ğŸ¯ Key Tasks Supported by Audio Language Models

Audio Language Models play a vital role in processing and understanding human speech. Below are the key tasks these models support:

### 1. **ğŸ“ Automatic Speech Recognition (ASR)**
   - Transcribes spoken words into written text.
   - Applications: Voice assistants, transcription services, and real-time captioning.

### 2. **ğŸŒ Multilingual Speech Recognition**
   - Recognizes and transcribes speech in multiple languages.
   - Applications: Global communication, language learning tools, and multilingual customer support.

### 3. **ğŸ”„ Speech Translation**
   - Translates spoken language into another language in real-time or offline.
   - Applications: Cross-language communication, travel assistants, and international conferences.

### 4. **ğŸ—£ï¸ Text-to-Speech (TTS) Conversion**
   - Converts written text into human-like speech.
   - Applications: Audiobooks, accessibility tools for visually impaired users, and voiceovers.

### 5. **ğŸ‘¤ Speaker Identification**
   - Identifies individual speakers from their voice.
   - Applications: Voice biometrics, security systems, and personalized voice assistants.

### 6. **ğŸ‘¥ Speaker Diarization**
   - Distinguishes and labels different speakers in an audio recording.
   - Applications: Meeting transcription, multi-speaker podcasts, and conference recordings.

### 7. **ğŸ”Š Emotion Recognition**
   - Detects emotions from speech signals.
   - Applications: Call center analysis, mental health monitoring, and gaming interactions.

### 8. **ğŸ§ Audio Enhancement**
   - Improves the quality of audio signals by removing noise or improving clarity.
   - Applications: Teleconferencing, podcast production, and hearing aids.

### 9. **ğŸ” Keyword Spotting**
   - Detects specific keywords or phrases in audio streams.
   - Applications: Wake-word detection (e.g., "Hey Siri"), surveillance, and targeted audio analysis.

### 10. **ğŸ§  Sentiment Analysis from Speech**
   - Analyzes the sentiment (positive, neutral, or negative) conveyed through speech.
   - Applications: Customer feedback analysis, social interactions, and content moderation.

### 11. **ğŸ“Š Speech Analytics**
   - Extracts insights such as word usage, speech pace, and patterns from audio data.
   - Applications: Business analytics, interview analysis, and training evaluations.

### 12. **ğŸ® Voice Control for Devices**
   - Enables interaction with devices or systems using voice commands.
   - Applications: Smart home devices, gaming controls, and industrial automation.

---

These tasks demonstrate the versatility and importance of audio language models across industries. Whether for accessibility, communication, or business applications, these models transform how we interact with technology and audio data.
