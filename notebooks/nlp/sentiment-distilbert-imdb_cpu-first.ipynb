{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Analysis \u2014 DistilBERT on IMDB\n",
        "**TL;DR:** Classify IMDB movie reviews with a CPU-first DistilBERT pipeline and prep for LoRA fine-tuning.\n",
        "\n",
        "**Models & Datasets:** [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) (Apache-2.0), [IMDB](https://huggingface.co/datasets/imdb) (CC BY-NC 4.0)\n",
        "**Run Profiles:** \ud83d\udda5\ufe0f CPU | \ud83c\udf4e Metal (Apple Silicon) | \ud83e\uddea Colab/T4 | \u26a1 CUDA GPU\n",
        "**Env (minimal):** python>=3.10, transformers, datasets, evaluate, accelerate (optional: peft, bitsandbytes, timm, diffusers)\n",
        "**Colab:** [Open in Colab](https://colab.research.google.com/github/SSusantAchary/Hands-On-Huggingface-AI-Models/blob/main/notebooks/nlp/sentiment-distilbert-imdb_cpu-first.ipynb)\n",
        "\n",
        "**Switches (edit in one place):**\n",
        "- `device` = {\"cpu\",\"mps\",\"cuda\"}\n",
        "- `precision` = {\"fp32\",\"fp16\",\"bf16\",\"int8\",\"4bit\"}  (apply only if supported)\n",
        "- `context_len` / `image_res` / `batch_size`\n",
        "\n",
        "**Footprint & Speed (fill after run):**\n",
        "- Peak RAM: TODO\n",
        "- Peak VRAM: TODO (if GPU)\n",
        "- TTFB: TODO, Throughput: TODO, Load time: TODO\n",
        "\n",
        "**Gotchas:** Metal backend falls back to CPU if MPS unavailable ([Fixes & Tips](../fixes-and-tips/metal-backend-fallback.md))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Setup\n",
        "Configure device toggles, load a small IMDB slice, and prepare utility helpers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "import json\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from evaluate import load as load_metric\n",
        "from transformers import pipeline\n",
        "\n",
        "from notebooks._templates.measure import append_benchmark_row, measure_memory_speed\n",
        "\n",
        "DEVICE_PREFERENCE = os.environ.get(\"HF_DEVICE\", \"cpu\")\n",
        "PRECISION = os.environ.get(\"HF_PRECISION\", \"fp32\")\n",
        "BATCH_SIZE = int(os.environ.get(\"HF_BATCH\", \"4\"))\n",
        "\n",
        "def resolve_device(preference: str = \"cpu\") -> str:\n",
        "    if preference == \"cuda\" and torch.cuda.is_available():\n",
        "        return \"cuda:0\"\n",
        "    if preference == \"mps\" and torch.backends.mps.is_available():\n",
        "        return \"mps\"\n",
        "    return \"cpu\"\n",
        "\n",
        "DEVICE = resolve_device(DEVICE_PREFERENCE)\n",
        "print(f\"Using device={DEVICE} (precision={PRECISION})\")\n",
        "\n",
        "DATASET_ID = \"imdb\"\n",
        "MODEL_ID = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "OUTPUT_DIR = Path(\"outputs\") / \"sentiment-distilbert-imdb\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "dataset = load_dataset(DATASET_ID, split=\"test[:16]\")\n",
        "sample = dataset.shuffle(seed=42).select(range(BATCH_SIZE))\n",
        "texts = sample[\"text\"]\n",
        "labels = sample[\"label\"]\n",
        "\n",
        "label_map = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "print(f\"Loaded {len(texts)} samples for smoke run.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference & Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "load_start = time.perf_counter()\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=MODEL_ID,\n",
        "    device=DEVICE,\n",
        "    top_k=None,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    return_all_scores=True,\n",
        ")\n",
        "load_time = time.perf_counter() - load_start\n",
        "\n",
        "all_scores = classifier(texts)\n",
        "predictions = []\n",
        "for idx, scores in enumerate(all_scores):\n",
        "    sorted_scores = sorted(scores, key=lambda item: item[\"score\"], reverse=True)\n",
        "    top = sorted_scores[0]\n",
        "    predictions.append(\n",
        "        {\n",
        "            \"text\": texts[idx][:120].replace(\"\\n\", \" \"),\n",
        "            \"true_label\": label_map[labels[idx]],\n",
        "            \"pred_label\": top[\"label\"],\n",
        "            \"pred_score\": round(top[\"score\"], 4),\n",
        "            \"neg_prob\": round(sorted_scores[0][\"score\"] if sorted_scores[0][\"label\"] == \"NEGATIVE\" else sorted_scores[1][\"score\"], 4),\n",
        "            \"pos_prob\": round(sorted_scores[0][\"score\"] if sorted_scores[0][\"label\"] == \"POSITIVE\" else sorted_scores[1][\"score\"], 4),\n",
        "        }\n",
        "    )\n",
        "\n",
        "df = pd.DataFrame(predictions)\n",
        "display(df)\n",
        "\n",
        "roc_auc = load_metric(\"roc_auc\")\n",
        "f1_metric = load_metric(\"f1\")\n",
        "preds = [0 if row[\"pred_label\"] == \"NEGATIVE\" else 1 for row in predictions]\n",
        "roc_score = roc_auc.compute(\n",
        "    references=labels,\n",
        "    prediction_scores=[row[\"pos_prob\"] for row in predictions],\n",
        ")[\"roc_auc\"]\n",
        "f1_score = f1_metric.compute(predictions=preds, references=labels)[\"f1\"]\n",
        "\n",
        "print(f\"ROC-AUC: {roc_score:.3f} | F1: {f1_score:.3f}\")\n",
        "\n",
        "predictions_path = OUTPUT_DIR / \"predictions.csv\"\n",
        "df.to_csv(predictions_path, index=False)\n",
        "print(f\"Saved predictions to {predictions_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measurement\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "def run_inference(recorder):\n",
        "    outputs = classifier(texts, batch_size=BATCH_SIZE, truncation=True, padding=True)\n",
        "    if outputs:\n",
        "        recorder.mark_first_token()\n",
        "    recorder.add_items(len(outputs))\n",
        "\n",
        "metrics = measure_memory_speed(run_inference)\n",
        "\n",
        "def fmt(value, digits=4):\n",
        "    if value in (None, \"\", float(\"inf\")):\n",
        "        return \"\"\n",
        "    return f\"{value:.{digits}f}\"\n",
        "\n",
        "try:\n",
        "    repo_commit = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], text=True).strip()\n",
        "except Exception:  # noqa: BLE001\n",
        "    repo_commit = \"\"\n",
        "\n",
        "append_benchmark_row(\n",
        "    task=\"sentiment-imdb\",\n",
        "    model_id=MODEL_ID,\n",
        "    dataset=DATASET_ID,\n",
        "    sequence_or_image_res=\"256-tokens\",\n",
        "    batch=str(BATCH_SIZE),\n",
        "    peak_ram_mb=fmt(metrics.get(\"peak_ram_mb\"), 2),\n",
        "    peak_vram_mb=fmt(metrics.get(\"peak_vram_mb\"), 2),\n",
        "    load_time_s=fmt(load_time, 2),\n",
        "    ttfb_s=fmt(metrics.get(\"ttfb_s\"), 3),\n",
        "    tokens_per_s_or_images_per_s=fmt(metrics.get(\"throughput_per_s\"), 3),\n",
        "    precision=PRECISION,\n",
        "    notebook_path=\"notebooks/nlp/sentiment-distilbert-imdb_cpu-first.ipynb\",\n",
        "    repo_commit=repo_commit,\n",
        ")\n",
        "\n",
        "with open(OUTPUT_DIR / \"metrics.json\", \"w\", encoding=\"utf-8\") as fp:\n",
        "    json.dump(metrics, fp, indent=2)\n",
        "metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Summary\n",
        "        - Observations: TODO\n",
        "        - Metrics captured: see `benchmarks/matrix.csv`\n",
        "\n",
        "        ## Next Steps\n",
        "        - TODOs: fill in after benchmarking\n",
        "\n",
        "        ## Repro\n",
        "        - Seed: 42 (set in measurement cell)\n",
        "        - Libraries: captured via `detect_env()`\n",
        "        - Notebook path: `notebooks/nlp/sentiment-distilbert-imdb_cpu-first.ipynb`\n",
        "        - Latest commit: populated automatically when appending benchmarks (if git available)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}