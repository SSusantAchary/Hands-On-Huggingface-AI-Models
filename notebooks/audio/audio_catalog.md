# Audio Notebook Catalog

| Model | Use case | Deps | Hardware | RAM | Notes | Notebook | Code |
|---|---|---|---|---|---|---|---|
| [Whisper Tiny](https://huggingface.co/openai/whisper-tiny)<br><sub>openai/whisper-tiny</sub> | ASR on short clips (EN/multilingual) | transformers, torchaudio, soundfile | CPU/GPU/MLX | <4GB | Install ffmpeg; good CPU baseline | audio/audio_notebooks/audio-01-whisper-tiny.ipynb | üñ•Ô∏è [Whisper tiny/base ASR (HF pipeline)](https://github.com/huggingface/notebooks/blob/main/examples/automatic_speech_recognition.ipynb) |
| [Wav2Vec2 Base 960h](https://huggingface.co/facebook/wav2vec2-base-960h)<br><sub>facebook/wav2vec2-base-960h</sub> | ASR baseline (LibriSpeech-style) | transformers, torchaudio | CPU/GPU/MLX | 4‚Äì8GB | Works on CPU; add CTC decoding note | audio/audio_notebooks/audio-02-wav2vec2-base-960h.ipynb | üöÄ [Whisper fine-tuning (English subset)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/asr_fine_tuning_whisper.ipynb) |
| [Whisper Base](https://huggingface.co/openai/whisper-base)<br><sub>openai/whisper-base</sub> | Balanced ASR quality vs speed | transformers, torchaudio, soundfile | CPU/GPU/MLX | 4‚Äì8GB | Use beam size 1 on CPU; ffmpeg needed | audio/audio_notebooks/audio-03-whisper-base.ipynb | üñ•Ô∏è [wav2vec2 ASR (base-960h)](https://github.com/huggingface/notebooks/blob/main/examples/wav2vec2_asr.ipynb) |
| [Whisper Small](https://huggingface.co/openai/whisper-small)<br><sub>openai/whisper-small</sub> | Improved ASR accuracy | transformers, torchaudio, soundfile | CPU/GPU/MLX | 8‚Äì16GB | GPU recommended; add language settings | audio/audio_notebooks/audio-04-whisper-small.ipynb | üöÄ [HuBERT audio classification (SUPERB)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification_superb.ipynb) |
| [Whisper Medium](https://huggingface.co/openai/whisper-medium)<br><sub>openai/whisper-medium</sub> | High accuracy ASR | transformers, torchaudio, soundfile | CPU/GPU | 16‚Äì32GB | Plan quantization; GPU strongly advised | audio/audio_notebooks/audio-05-whisper-medium.ipynb | üöÄ [Keyword spotting (Speech Commands)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/keyword_spotting.ipynb) |
| [Wav2Vec2 XLSR EN](https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english)<br><sub>jonatasgrosman/wav2vec2-large-xlsr-53-english</sub> | Multilingual ASR fine-tune | transformers, torchaudio | CPU/GPU | 8‚Äì16GB | Large memory; add vocab mapping | audio/audio_notebooks/audio-06-wav2vec2-xlsr-en.ipynb | üöÄ [Speaker verification (ECAPA-TDNN, SpeechBrain)](https://colab.research.google.com/github/speechbrain/speechbrain/blob/develop/recipes/VoxCeleb/SpeakerRec/SVECAPA.ipynb) |
| [HuBERT Large](https://huggingface.co/facebook/hubert-large-ls960-ft)<br><sub>facebook/hubert-large-ls960-ft</sub> | Self-supervised ASR feature extractor | transformers, torchaudio | CPU/GPU | 8‚Äì16GB | Great for finetuning; MIT license | audio/audio_notebooks/audio-07-hubert-large.ipynb | üöÄ [Speaker diarization (pyannote)](https://colab.research.google.com/github/pyannote/pyannote-audio/blob/develop/tutorials/diarization_api.ipynb) |
| [WavLM Base Plus](https://huggingface.co/microsoft/wavlm-base-plus)<br><sub>microsoft/wavlm-base-plus</sub> | Speech enhancement and ASR | transformers, torchaudio | CPU/GPU | 4‚Äì8GB | Use speechbrain recipes; MIT license | audio/audio_notebooks/audio-08-wavlm-base-plus.ipynb | üöÄ [Audio emotion recognition (SUPERB ER)](https://colab.research.google.com/github/superbbenchmark/superb/blob/master/notebook/SUPERB_ER_demo.ipynb) |
| [WavLM Large](https://huggingface.co/microsoft/wavlm-large)<br><sub>microsoft/wavlm-large</sub> | Speaker diarization features | transformers, torchaudio | CPU/GPU | 8‚Äì16GB | Heavy but accurate; add VAD tip | audio/audio_notebooks/audio-09-wavlm-large.ipynb | üöÄ [TTS (Coqui-TTS basic colab)](https://colab.research.google.com/github/coqui-ai/TTS/blob/dev/notebooks/TTS_inference_demo.ipynb) |
| [HuBERT Emotion](https://huggingface.co/superb/hubert-base-superb-er)<br><sub>superb/hubert-base-superb-er</sub> | Emotion classification | transformers, torchaudio | CPU/GPU | 4‚Äì8GB | Requires torchaudio>=2.1; check labels | audio/audio_notebooks/audio-10-hubert-emotion.ipynb | üöÄ [Voice activity detection (pyannote VAD)](https://colab.research.google.com/github/pyannote/pyannote-audio/blob/develop/tutorials/pipeline_demo.ipynb) |
| [Wav2Vec2 Speaker ID](https://huggingface.co/superb/wav2vec2-base-superb-sid)<br><sub>superb/wav2vec2-base-superb-sid</sub> | Speaker identification | transformers, torchaudio | CPU/GPU | 4‚Äì8GB | Add enrollment pipeline; MIT | audio/audio_notebooks/audio-11-wav2vec2-speaker-id.ipynb | üöÄ [WavLM ASR / embeddings demo](https://colab.research.google.com/github/microsoft/unilm/blob/master/wavlm/notebooks/WavLM_Demo.ipynb) |
| [UrbanSound8K ECAPA](https://huggingface.co/speechbrain/urbansound8k_ecapa)<br><sub>speechbrain/urbansound8k_ecapa</sub> | Urban sound classification | speechbrain, torchaudio | CPU/GPU | 4‚Äì8GB | Install ffmpeg; add data download step | audio/audio_notebooks/audio-12-urbansound8k-ecapa.ipynb | üöÄ [XLS-R multilingual ASR](https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Fine_tune_XLSR_Wav2Vec2_on_Arabic_ASR_with_Common_Voice.ipynb) |
| [ECAPA VoxCeleb](https://huggingface.co/speechbrain/spkrec-ecapa-voxceleb)<br><sub>speechbrain/spkrec-ecapa-voxceleb</sub> | Speaker verification embeddings | speechbrain, torchaudio | CPU/GPU | 4‚Äì8GB | Add score calibration tip | audio/audio_notebooks/audio-13-ecapa-voxceleb.ipynb | üöÄ [Audio tagging (UrbanSound8K with HF)](https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/audio_classification_hf.ipynb) |
| [Wav2Vec2 Emotion](https://huggingface.co/speechbrain/emotion-recognition-wav2vec2-IEMOCAP)<br><sub>speechbrain/emotion-recognition-wav2vec2-IEMOCAP</sub> | Emotion recognition pipeline | speechbrain, torchaudio | CPU/GPU | 8‚Äì16GB | GPU improves speed; MIT license | audio/audio_notebooks/audio-14-wav2vec2-emotion.ipynb | üöÄ [Streaming ASR with transformers](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/asr_streaming.ipynb) |
| [Speech Commands CNN](https://huggingface.co/speechbrain/google-speech-commands-cnn)<br><sub>speechbrain/google-speech-commands-cnn</sub> | Keyword spotting quickstart | speechbrain, torchaudio | CPU/GPU/MLX | <4GB | Great edge baseline; add noise aug | audio/audio_notebooks/audio-15-speech-commands-cnn.ipynb | üöÄ [Textless NLP (HuBERT units) demo](https://colab.research.google.com/github/facebookresearch/textlesslib/blob/main/notebooks/demo.ipynb) |
| [MIMIC VoiceBank](https://huggingface.co/speechbrain/mtl-mimic-voicebank)<br><sub>speechbrain/mtl-mimic-voicebank</sub> | Speech enhancement baseline | speechbrain, torchaudio | CPU/GPU | 4‚Äì8GB | Needs noise dataset; MIT license | audio/audio_notebooks/audio-16-mimic-voicebank.ipynb | üöÄ [Music tagging with AST](https://colab.research.google.com/github/qiuqiangkong/audioset_tagging_cnn/blob/master/colab/ast_audioset_demo.ipynb) |
| [SpeechT5 TTS](https://huggingface.co/microsoft/speecht5_tts)<br><sub>microsoft/speecht5_tts</sub> | Text-to-speech neural | transformers, torchaudio | CPU/GPU | 8‚Äì16GB | Requires HiFi-GAN vocoder; MIT license | audio/audio_notebooks/audio-17-speecht5-tts.ipynb | üöÄ [Silero VAD + ASR integration](https://colab.research.google.com/github/snakers4/silero-models/blob/master/examples/silero_vad_colab.ipynb) |
| [XTTS v2](https://huggingface.co/coqui/XTTS-v2)<br><sub>coqui/XTTS-v2</sub> | Multi-speaker TTS | TTS, torch | CPU/GPU | 16‚Äì32GB | Check Coqui license; needs ffmpeg | audio/audio_notebooks/audio-18-xtts-v2.ipynb | üöÄ [Audio augmentation & features (librosa)](https://colab.research.google.com/github/musikalkemist/AudioSignalProcessingForML/blob/master/03-Audio-Data-Augmentation.ipynb) |
| [VITS LJSpeech](https://huggingface.co/espnet/kan-bayashi_ljspeech_vits)<br><sub>espnet/kan-bayashi_ljspeech_vits</sub> | Fast TTS baseline | espnet, torchaudio | CPU/GPU | 8‚Äì16GB | Warm up for better quality; MIT | audio/audio_notebooks/audio-19-vits-ljspeech.ipynb | üöÄ [torchaudio pipeline tutorial](https://colab.research.google.com/github/pytorch/tutorials/blob/main/beginner_source/audio_classifier_tutorial.ipynb) |
| [MMS TTS EN](https://huggingface.co/facebook/mms-tts-eng)<br><sub>facebook/mms-tts-eng</sub> | Multilingual MMS TTS | transformers, torchaudio | CPU/GPU | 8‚Äì16GB | License review: MMS; add phoneme note | audio/audio_notebooks/audio-20-mms-tts-en.ipynb | üöÄ [Audio to embeddings (CLAP/LAION)](https://colab.research.google.com/github/LAION-AI/CLAP/blob/main/notebooks/CLAP_demo.ipynb) |

_Source of truth: `/meta/notebook_catalog.csv`._
